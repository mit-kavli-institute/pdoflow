name: Scheduled Tests

on:
  schedule:
    # Run tests daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      hypothesis_profile:
        description: 'Hypothesis profile to use'
        required: false
        default: 'ci'
        type: choice
        options:
          - default
          - ci
          - dev
          - debug

env:
  HYPOTHESIS_PROFILE: ${{ inputs.hypothesis_profile || 'ci' }}

jobs:
  full-test-suite:
    name: Full Test Suite - Python ${{ matrix.python-version }}
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.9", "3.10", "3.11", "3.12"]

    services:
      postgres:
        image: postgres:14-alpine
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: testing
          POSTGRES_DB: postgres
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install tox

    - name: Run full test suite
      env:
        POSTGRES_HOST: localhost
        POSTGRES_PORT: 5432
        POSTGRES_USER: postgres
        POSTGRES_PASSWORD: testing
        POSTGRES_DB: postgres
      run: |
        # Run all tox environments for this Python version
        tox -e clean,py$(echo ${{ matrix.python-version }} | tr -d .),report

    - name: Upload test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: test-results-${{ matrix.python-version }}
        path: |
          .coverage.*
          htmlcov/
          coverage.json
        retention-days: 30

  performance-tests:
    name: Performance Regression Tests
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:14-alpine
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: testing
          POSTGRES_DB: postgres
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"
        pip install pytest-benchmark memory-profiler

    - name: Run performance tests
      env:
        POSTGRES_HOST: localhost
        POSTGRES_PORT: 5432
        POSTGRES_USER: postgres
        POSTGRES_PASSWORD: testing
        POSTGRES_DB: postgres
      run: |
        # Run tests with profiling focus
        pytest tests/test_profiling.py -v --benchmark-only --benchmark-autosave

    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results
        path: .benchmarks/
        retention-days: 90

  security-scan:
    name: Security Vulnerability Scan
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install safety bandit

    - name: Run safety check
      continue-on-error: true
      run: |
        pip install -e ".[dev]"
        safety check --json > safety-report.json || true

    - name: Run bandit security scan
      continue-on-error: true
      run: |
        bandit -r src/ -f json -o bandit-report.json || true

    - name: Upload security reports
      uses: actions/upload-artifact@v4
      with:
        name: security-reports
        path: |
          safety-report.json
          bandit-report.json
        retention-days: 30

  notify-failures:
    name: Notify Test Failures
    needs: [full-test-suite, performance-tests, security-scan]
    runs-on: ubuntu-latest
    if: failure()

    steps:
    - name: Create issue for test failure
      uses: actions/github-script@v7
      with:
        script: |
          const date = new Date().toISOString().split('T')[0];
          const title = `Scheduled tests failed on ${date}`;

          // Check if issue already exists
          const issues = await github.rest.issues.listForRepo({
            owner: context.repo.owner,
            repo: context.repo.repo,
            state: 'open',
            labels: 'scheduled-test-failure'
          });

          const existingIssue = issues.data.find(issue => issue.title === title);

          if (!existingIssue) {
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: title,
              body: `## Scheduled Test Failure\n\nThe scheduled test run failed on ${date}.\n\n[View workflow run](${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})`,
              labels: ['scheduled-test-failure', 'automated']
            });
          }
